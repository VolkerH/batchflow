{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SystemDeepGalerkin-model: solving systems of PDEs with NN's\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome! In this tutorial you'll learn how to solve systems of partial differential equations (PDEs) with neural networks using `SystemDeepGalerkin`-model from `BatchFlow`, inspired by the paper [DGM: A deep learning algorithm for solving partial differential equations](http://arxiv.org/abs/1708.07469).\n",
    "\n",
    "It is expected for you to be familiar with `DeepGalerkin` model. If you haven't already, check our [DeepGalerkin tutorial](./09_solving_PDE_with_NN.ipynb) to learn how to solve single PDE with neural networks.\n",
    "\n",
    "**Note**: `SystemDeepGalerkin` is written in [TensorFlow](https://www.tensorflow.org/). Throughout the notebook `tf` will stand for `TensoFlow`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, `SystemDeepGalerkin` is able to solve system of equations of up to the second order with constant coefficients with various boundary and initial conditions. In most general form, the problem looks as follows:\n",
    "\n",
    "<a id='eq'></a>\n",
    "$$\n",
    "\\begin{cases}\n",
    "\\sum_f \\Bigg\\{ \\sum_i a_{mfi} \\dfrac{\\partial u_{mf}}{\\partial x_i} + \\sum_{i j} b_{ m f i j} \\dfrac{\\partial^2 u_{mf}}{\\partial x_i \\partial x_i} \\Bigg\\}  = Q_{m}(x), \\\\ m \\in [0 \\dots M], \\\\\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "where indices $m, f$ stand for index of equation and unknown function respectively. $M$ is the total number of equations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main idea of `SystemDeepGalerkin`  stays the same: to fit the parameters $\\theta$ of network $net(x; \\theta)$ so that the difference between left-hand-sides (lhs) and right-hand-size (rhs) is small:\n",
    "<a id='dist'></a>\n",
    "$$\n",
    "e_m(x) = \\sum_f \\Bigg\\{ \\sum_i a_{mfi} \\dfrac{\\partial net(x; \\theta)_{f}}{\\partial x_i} + \\sum_{i j} b_{ m f i j} \\dfrac{\\partial^2 net(x; \\theta)_{f}}{\\partial x_i \\partial x_i} \\Bigg\\} - Q_{m}(x),\n",
    "$$\n",
    "$$\n",
    "Loss(\\theta) = \\int\\limits_{\\Omega} L\\left[\\sum_m e_m(x)\\right] \\mathcal{P}( d x),\n",
    "$$\n",
    "$$\n",
    "Loss(\\theta) \\rightarrow \\min\\limits_{\\theta}.\n",
    "$$\n",
    "\n",
    "The big change from `DeepGalerkin` is that neural network has to have multiple outputs (one for each unknown function).\n",
    "\n",
    "**Note:** In practice, $Loss(\\theta)$ is estimated on a sample(batch) of points $\\{(x^i_1,\\dots, x^i_n)\\}_{i=1,\\dots,N}$.\n",
    "As the distribution $\\mathcal{P}$ is not fixed, any sampling scheme can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring `DeepGalerkin`\n",
    "As in previous model, configurating `SystemDeepGalerkin` comes to:\n",
    "* specifying PDE problem via `pde` key\n",
    "* setting up neural network architecture (and additional parameters)\n",
    "* configuring how to form batches of training data and feed them into the training loop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PDE`-dict\n",
    "To set up PDE problem, you need to specify:\n",
    "* coefficients of every equation. That has to be done via `form` key, but unlike `DeepGalerkin`, every value in it has to be `np.array`\n",
    "* `rhs`: tf_callable. The returned value must be list of appropriate length (same as number of equations)  \n",
    "\n",
    "There are also optional parameters:\n",
    "* `domain` for every variable\n",
    "* `initial_condition`: initial state and initial rate\n",
    "* `time_multiplier`: can be either string or list of strings. In former case, same `time_multiplier` is applied for binding initial conditions. The latter case corresponds to individual `time_multiplier` strategies. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network architecture\n",
    "\n",
    "As mentioned earlier, `SystemDeepGalerkin` approximates multiple unknown functions via one neural network with multiple outputs. It is easy to see that such neural network can be represented as multiple single-output networks with different layers following some common ones.\n",
    "\n",
    "To configure model, you have to specify:\n",
    "\n",
    "* `body`. Parameters of shared part of network. As always, you can use convinient [batchflow's syntax](https://analysiscenter.github.io/batchflow/intro/tf_layers.html). For instance, this combination of keys\n",
    "```\n",
    "'body':{'layout' : 'fa fa f',\n",
    "        'units' : [10, 15, 1],\n",
    "        'activation' : [tf.nn.tanh, tf.nn.tanh]}\n",
    "```\n",
    "corresponds to a `f`ully-connected network with two hidden layers (of 10 and 15 units), one output-unit and two `tanh`-`a`ctivations.\n",
    "\n",
    "* `head`. Configuration of individual layers for every output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: solving system of 2 equations with `SystemDeepGalerkin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "import matplotlib.pyplot as plt\n",
    "from batchflow.models.tf import SystemDeepGalerkin\n",
    "from batchflow import Pipeline, L, F, V, DatasetIndex, Dataset\n",
    "import numpy as np\n",
    "from batchflow import NumpySampler\n",
    "from tqdm import tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* two equations of the first order with initial conditions:\n",
    "\n",
    "$$\n",
    "\\begin{cases}\n",
    "u_1(t) + \\dfrac{\\partial u_2(t)}{ \\partial t} = 0 \\\\\n",
    "u_2(t) + \\dfrac{\\partial u_1(t)}{ \\partial t} = 2 \\cos(t)\n",
    "\\end{cases}\n",
    "\\\\ \n",
    "u_1(0)=0, \\quad u_2(0)=1.\n",
    "$$\n",
    "\n",
    "It is easy to see, that $u_1(t) = \\sin(t)$ and $u_2(t) = \\cos(t)$ satisfy both system of equations and initial conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up shapes of coefficients of left-hand-sides:\n",
    "# 'M' stands for number of equations\n",
    "# 'N' stands for number of variables\n",
    "M, N = 2, 1\n",
    "d0 = np.zeros((M, M))\n",
    "d1 = np.zeros((M, M, N))\n",
    "d2 = np.zeros((M, M, N, N))\n",
    "\n",
    "# The first index stands for equation number, the second one - for unknown function\n",
    "d0[0, 0] = 1\n",
    "d1[0, 1, 0] = 1\n",
    "\n",
    "d0[1, 1] = 1\n",
    "d1[1, 0, 0] = 1\n",
    "\n",
    "# Specifying problem\n",
    "# Note that both 'rhs' and 'initial_condition' return callable that returns list\n",
    "# Also, we can use 'polynomial' time_multiplier since we know that solutions have no asymptotes\n",
    "pde = {'form': {'d0': d0, 'd1': d1, 'd2': d2},\n",
    "       'rhs': lambda x: [tf.fill(tf.shape(x[:]), 0.0),\n",
    "                         2*tf.cos(x[:])],\n",
    "       'initial_condition': lambda x: [tf.constant(0.0, dtype='float32'),\n",
    "                                       tf.constant(1.0, dtype='float32')],\n",
    "       'time_multiplier': 'polynomial'}\n",
    "\n",
    "# Network-architecture and loss-function\n",
    "# 'body' configures common part for both unknown functions\n",
    "# 'head' specifies individual branches for every output\n",
    "body = {'layout': 'fa',\n",
    "        'units': 40,\n",
    "        'activation': tf.nn.tanh}\n",
    "\n",
    "head = {'layout': 'fa fa' + 'f',\n",
    "        'units': [25, 25, 1],\n",
    "        'activation': [tf.nn.tanh]*2}\n",
    "\n",
    "loss = 'mse'\n",
    "\n",
    "# Put it all together in model-config\n",
    "config = {'pde': pde,\n",
    "          'body': body,\n",
    "          'head': head,\n",
    "          'loss': loss}  \n",
    "\n",
    "# Uniform sampling scheme\n",
    "s = NumpySampler('u', dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assemble training pipeline\n",
    "pipeline = (Pipeline()\n",
    "            .init_variable('loss', default=[])\n",
    "            .init_variable('dt', default=[])\n",
    "            .init_model('static', SystemDeepGalerkin, 'DG', config)\n",
    "            .train_model('DG',\n",
    "                         feed_dict={'points': L(s.sample, size=F(len))},\n",
    "                         fetches='loss',\n",
    "                         save_to=V('loss'), mode='a'))\n",
    "\n",
    "dsix = DatasetIndex(np.arange(100))\n",
    "pipeline_ds = Dataset(dsix) >> pipeline\n",
    "\n",
    "# Train the network on batches\n",
    "for i in tqdm_notebook(range(100)):\n",
    "    pipeline_ds.next_batch(30, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.plot(pipeline_ds.get_variable('loss')[:])\n",
    "plt.xlabel('iteration number', fontdict={'fontsize': 15})\n",
    "plt.ylabel('Loss',fontdict={'fontsize': 15})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch trained model\n",
    "dg = pipeline_ds.get_model_by_name('DG')\n",
    "\n",
    "# Plot true solutions and their approximations\n",
    "n_el = 100\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "pts = np.linspace(0, 1, n_el).reshape((n_el, 1))\n",
    "\n",
    "true_sin = [np.sin(t_) for t_ in pts]\n",
    "approxs_sin = dg.predict(feed_dict={'points': pts})[0]\n",
    "true_cos = [np.cos(t_) for t_ in pts]\n",
    "approxs_cos = dg.predict(feed_dict={'points': pts})[1]\n",
    "\n",
    "plt.plot(pts, true_sin, 'g--', linewidth=3, label='true sin')\n",
    "plt.plot(pts, approxs_sin.reshape(n_el, ), 'y', label='sin approximation')\n",
    "plt.plot(pts, true_cos, 'b--',  linewidth=3, label='true cos')\n",
    "plt.plot(pts, approxs_cos.reshape(n_el, ), 'r', label='cos approximation')\n",
    "\n",
    "ax.legend(loc='upper right', shadow=True, ncol=2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
