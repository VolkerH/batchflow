{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from batchflow.opensets import MNIST\n",
    "from batchflow.models.tf import TFModel\n",
    "from batchflow import Pipeline, L, F, V, D, B, DatasetIndex, Dataset, ImagesBatch, Config\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DownloadingDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      " http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "ExtractingExtracting /tmp/train-labels-idx1-ubyte.gz\n",
      " /tmp/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/t10k-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/t10k-images-idx3-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = MNIST(batch_class=ImagesBatch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decay_d = ('exp', {'learning_rate': 0.001,\n",
    "                   'decay_steps': 150,\n",
    "                   'decay_rate': 0.96})\n",
    "\n",
    "model_config = {'inputs': dict(images={'shape': (28, 28, 1)},\n",
    "                               labels={'classes': 10}),\n",
    "                'initial_block': {'layout': 'cna'*2,\n",
    "                                  'filters': [6]*2, 'kernel_size': [3]*2,\n",
    "                                  'inputs': 'images'},\n",
    "                'body': {'layout': 'nca nca',\n",
    "                         'filters': [8, 16],\n",
    "                         'kernel_size': [3, 3]},\n",
    "                'head': {'layout': 'Pfa'},\n",
    "                'loss': 'ce',\n",
    "                'optimizer': 'Adam',\n",
    "                'decay': decay_d,\n",
    "                'train_modes': {'all': {'optimizer': 'RMSProp', 'decay': decay_d},\n",
    "                                'body': {'optimizer': 'Adam', 'scope': 'body'},\n",
    "                                'head': {'optimizer': 'Adagrad', 'scope': 'head', 'decay': decay_d},\n",
    "                                'custom': {'optimizer': 'Adam', 'scope': '-initial_block/layer-0'}},\n",
    "                'head/units': 10\n",
    "}\n",
    "\n",
    "data_dict = {'images': B('images'),\n",
    "             'labels': B('labels')}\n",
    "\n",
    "train_pipeline = (mnist.train.p\n",
    "                 .init_variable('predictions')\n",
    "                 .to_array()\n",
    "                 .multiply(multiplier=1/255., preserve_type=False)\n",
    "                 .init_model('dynamic', TFModel, 'conv', config=model_config)\n",
    "                 .to_array()\n",
    "                 .train_model('conv', fetches='predictions', feed_dict=data_dict, \n",
    "                              train_mode='head', save_to=V('predictions'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "CURRENT KEY:  all\n",
      "SUBCONFIG:  {'optimizer': 'RMSProp', 'decay': ('exp', {'learning_rate': 0.001, 'decay_steps': 150, 'decay_rate': 0.96}), 'scope': ''}\n",
      "OPTIMIZER_:  <tensorflow.python.training.rmsprop.RMSPropOptimizer object at 0x7f3f98574a90> \n",
      "\n",
      "SCOPE COLLECTION\n",
      "<tf.Variable 'TFModel/initial_block/layer-0/conv2d/kernel:0' shape=(3, 3, 1, 6) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-0/conv2d/bias:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/kernel:0' shape=(3, 3, 6, 6) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/bias:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/kernel:0' shape=(3, 3, 6, 8) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/gamma:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/beta:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/kernel:0' shape=(3, 3, 8, 16) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/kernel:0' shape=(16, 10) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "\n",
      "\n",
      "\n",
      "CURRENT KEY:  body\n",
      "SUBCONFIG:  {'optimizer': 'Adam', 'scope': 'body', 'decay': ('exp', {'learning_rate': 0.001, 'decay_steps': 150, 'decay_rate': 0.96})}\n",
      "OPTIMIZER_:  <tensorflow.python.training.adam.AdamOptimizer object at 0x7f3f048a2240> \n",
      "\n",
      "SCOPE COLLECTION\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/kernel:0' shape=(3, 3, 6, 8) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/gamma:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/beta:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/kernel:0' shape=(3, 3, 8, 16) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "\n",
      "\n",
      "\n",
      "CURRENT KEY:  head\n",
      "SUBCONFIG:  {'optimizer': 'Adagrad', 'scope': 'head', 'decay': ('exp', {'learning_rate': 0.001, 'decay_steps': 150, 'decay_rate': 0.96})}\n",
      "OPTIMIZER_:  <tensorflow.python.training.adagrad.AdagradOptimizer object at 0x7f3f98574a90> \n",
      "\n",
      "SCOPE COLLECTION\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/kernel:0' shape=(16, 10) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "\n",
      "\n",
      "\n",
      "CURRENT KEY:  custom\n",
      "SUBCONFIG:  {'optimizer': 'Adam', 'scope': '-initial_block/layer-0', 'decay': ('exp', {'learning_rate': 0.001, 'decay_steps': 150, 'decay_rate': 0.96})}\n",
      "OPTIMIZER_:  <tensorflow.python.training.adam.AdamOptimizer object at 0x7f3f048a2240> \n",
      "\n",
      "SCOPE COLLECTION\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/kernel:0' shape=(3, 3, 6, 6) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/bias:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/kernel:0' shape=(3, 3, 6, 8) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/gamma:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/beta:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/kernel:0' shape=(3, 3, 8, 16) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/kernel:0' shape=(16, 10) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "\n",
      "\n",
      "\n",
      "CURRENT KEY:  \n",
      "SUBCONFIG:  {'optimizer': 'Adam', 'scope': '', 'decay': ('exp', {'learning_rate': 0.001, 'decay_steps': 150, 'decay_rate': 0.96})}\n",
      "OPTIMIZER_:  <tensorflow.python.training.adam.AdamOptimizer object at 0x7f3f98574a90> \n",
      "\n",
      "SCOPE COLLECTION\n",
      "<tf.Variable 'TFModel/initial_block/layer-0/conv2d/kernel:0' shape=(3, 3, 1, 6) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-0/conv2d/bias:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-1/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/kernel:0' shape=(3, 3, 6, 6) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-3/conv2d/bias:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/initial_block/layer-4/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/gamma:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-0/batch_normalization/beta:0' shape=(6,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/kernel:0' shape=(3, 3, 6, 8) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-1/conv2d/bias:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/gamma:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-3/batch_normalization/beta:0' shape=(8,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/kernel:0' shape=(3, 3, 8, 16) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/body/layer-4/conv2d/bias:0' shape=(16,) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/kernel:0' shape=(16, 10) dtype=float32_ref>\n",
      "<tf.Variable 'TFModel/head/layer-1/dense/bias:0' shape=(10,) dtype=float32_ref>\n",
      "{}\n",
      "CPU times: user 3.07 s, sys: 101 ms, total: 3.17 s\n",
      "Wall time: 2.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_b = train_pipeline.next_batch(256, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_pipeline.get_model_by_name('conv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = (mnist.test.p\n",
    "                 .import_model('conv', train_pipeline)\n",
    "                 .to_array()\n",
    "                 .multiply(multiplier=1/255., preserve_type=False)\n",
    "                 .init_model('dynamic', TFModel, 'conv', config=model_config)\n",
    "                 .to_array()\n",
    "                 .init_variable('result', init_on_each_run=list()) \n",
    "                 .predict_model('conv', fetches=['predictions', 'TFModel/body/Relu_1'], feed_dict=data_dict,\n",
    "                                save_to=V('result'), mode='a')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_pipeline.next_batch(10, n_epochs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline.get_variable('result')[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.graph.get_operations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModifiedTFModel(TFModel):\n",
    "    \n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.session = kwargs.get('session', None)\n",
    "        self.graph = tf.Graph() if self.session is None else self.session.graph\n",
    "        self._graph_context = None\n",
    "        self.is_training = None\n",
    "        self.global_step = None\n",
    "        self.loss = None\n",
    "        self.train_steps = None\n",
    "        self._train_lock = threading.Lock()\n",
    "        self._attrs = []\n",
    "        self._saver = None\n",
    "        self._to_classes = {}\n",
    "        self._inputs = {}\n",
    "        self.inputs = None\n",
    "\n",
    "        super().__init__(*args, **kwargs)    \n",
    "\n",
    "    def build(self, *args, **kwargs):\n",
    "        def _device_context():\n",
    "            if 'device' in self.config:\n",
    "                device = self.config.get('device')\n",
    "                context = self.graph.device(device)\n",
    "            else:\n",
    "                context = contextlib.ExitStack()\n",
    "            return context\n",
    "\n",
    "\n",
    "        with self.graph.as_default(), _device_context():\n",
    "            with tf.variable_scope(self.__class__.__name__):\n",
    "                with tf.variable_scope('globals'):\n",
    "                    if self.is_training is None:\n",
    "                        self.store_to_attr('is_training', tf.placeholder(tf.bool, name='is_training'))\n",
    "                    if self.global_step is None:\n",
    "                        self.store_to_attr('global_step', tf.Variable(0, trainable=False, name='global_step'))\n",
    "\n",
    "                config = self.build_config()\n",
    "                self._build(config)\n",
    "                if self.train_steps is None:\n",
    "                    self._make_loss(config)\n",
    "                    self.store_to_attr('loss', tf.losses.get_total_loss())\n",
    "\n",
    "                    ######################\n",
    "                    if config.get('train_modes') is None:\n",
    "                        config['train_modes'] = {}\n",
    "                    \n",
    "                    _decay = config.get('decay')\n",
    "                    _optimizer = config.get('optimizer')\n",
    "                    _scope = config.get('scope')\n",
    "                    if _optimizer is not None:\n",
    "                        config['train_modes'].update({'default': {'optimizer': _optimizer,\n",
    "                                                                  'decay': _decay,\n",
    "                                                                  'scope': _scope}})\n",
    "                    \n",
    "                    for key, subconfig in config.get('train_modes').items():\n",
    "                        if subconfig.get('optimizer') is None:\n",
    "                            subconfig.update({'optimizer': _optimizer})\n",
    "                        if subconfig.get('decay') is None:\n",
    "                            subconfig.update({'decay': _decay})\n",
    "                        if subconfig.get('scope') is None:\n",
    "                            subconfig.update({'scope': _scope})\n",
    "                    \n",
    "\n",
    "                    train_steps = {}\n",
    "                    for key, subconfig in config['train_modes'].items():\n",
    "                        print('\\n\\n\\nCURRENT KEY: ', key)\n",
    "                        print('\\nSUBCONFIG: ', subconfig)\n",
    "                        optimizer_ = self._make_optimizer(subconfig)\n",
    "                        print('\\nOPTIMIZER_: ', optimizer_)\n",
    "                        \n",
    "                        if optimizer_:\n",
    "                            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "                            with tf.control_dependencies(update_ops):\n",
    "    \n",
    "                                scope = subconfig.get('scope')\n",
    "                                var_scope = self.__class__.__name__ + '/' + scope\n",
    "                                scope_collection = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                                                     var_scope)\n",
    "                                \n",
    "                                pprint(scope_collection)\n",
    "                                train_step_ = optimizer_.minimize(self.loss,\n",
    "                                                                  global_step=self.global_step,\n",
    "                                                                  var_list=scope_collection)\n",
    "                                train_steps.update({key: train_step_})\n",
    "                    \n",
    "                    self.store_to_attr('train_steps', train_steps)\n",
    "                    print('\\n\\nTRAIN_STEPS: ', self.train_steps)\n",
    "                    \n",
    "                    ######################\n",
    "                else:\n",
    "                    self.store_to_attr('train_step', self.train_steps)\n",
    "\n",
    "            if self.session is None:\n",
    "                self.create_session(config)\n",
    "                self.reset()\n",
    "                \n",
    "    @classmethod\n",
    "    def default_config(cls):\n",
    "        config = Config()\n",
    "        config['inputs'] = {}\n",
    "        config['initial_block'] = {}\n",
    "        config['body'] = {}\n",
    "        config['head'] = {}\n",
    "        config['predictions'] = None\n",
    "        config['output'] = None\n",
    "        config['optimizer'] = ('Adam', dict())\n",
    "        config['decay'] = (None, dict())\n",
    "        config['scope'] = ''\n",
    "        config['common'] = {'batch_norm': {'momentum': .1}}\n",
    "\n",
    "        return config                \n",
    "                \n",
    "                \n",
    "    def train(self, fetches=None, feed_dict=None, use_lock=False, train_mode='default', **kwargs):\n",
    "        print('\\n\\n TRAIN_MODE IS: ', train_mode)\n",
    "        print('\\n\\n CURRENT train_step: ', self.train_steps[train_mode])\n",
    "        with self.graph.as_default():\n",
    "            feed_dict = {} if feed_dict is None else feed_dict\n",
    "            feed_dict = {**feed_dict, **kwargs}\n",
    "            _feed_dict = self._fill_feed_dict(feed_dict, is_training=True)\n",
    "            if fetches is None:\n",
    "                _fetches = tuple()\n",
    "            else:\n",
    "                _fetches = self._fill_fetches(fetches, default=None)\n",
    "\n",
    "            if use_lock:\n",
    "                self._train_lock.acquire()\n",
    "\n",
    "            _all_fetches = []\n",
    "            \n",
    "            #####\n",
    "            if self.train_steps:\n",
    "                _all_fetches += [self.train_steps[train_mode]]\n",
    "                \n",
    "                \n",
    "                #######\n",
    "            if _fetches is not None:\n",
    "                _all_fetches += [_fetches]\n",
    "            if len(_all_fetches) > 0:\n",
    "                _, output = self.session.run(_all_fetches, feed_dict=_feed_dict)\n",
    "            else:\n",
    "                output = None\n",
    "\n",
    "            if use_lock:\n",
    "                self._train_lock.release()\n",
    "\n",
    "            return self._fill_output(output, _fetches)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
