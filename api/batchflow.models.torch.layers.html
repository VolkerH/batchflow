

<!doctype html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="X-UA-Compatible" content="IE=Edge" />
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <title>batchflow.models.torch.layers &#8212; BatchFlow 0.3.0 documentation</title>
    <link rel="stylesheet" href="../_static/bizstyle.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript" id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="../_static/language_data.js"></script>
    <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/javascript" src="../_static/bizstyle.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="dataset.research" href="batchflow.research.html" />
    <link rel="prev" title="batchflow.models.torch" href="batchflow.models.torch.html" />
    <meta name="viewport" content="width=device-width,initial-scale=1.0">
    <!--[if lt IE 9]>
    <script type="text/javascript" src="_static/css3-mediaqueries.js"></script>
    <![endif]-->
  </head><body>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="batchflow.research.html" title="dataset.research"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="batchflow.models.torch.html" title="batchflow.models.torch"
             accesskey="P">previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">BatchFlow 0.3.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="batchflow.html" >API</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="batchflow.models.html" >batchflow.models</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="batchflow.models.torch.html" accesskey="U">batchflow.models.torch</a> &#187;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
  <h4>Previous topic</h4>
  <p class="topless"><a href="batchflow.models.torch.html"
                        title="previous chapter">batchflow.models.torch</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="batchflow.research.html"
                        title="next chapter">dataset.research</a></p>
  <div role="note" aria-label="source link">
    <h3>This Page</h3>
    <ul class="this-page-menu">
      <li><a href="../_sources/api/batchflow.models.torch.layers.rst.txt"
            rel="nofollow">Show Source</a></li>
    </ul>
   </div>
<div id="searchbox" style="display: none" role="search">
  <h3>Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    </div>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="module-batchflow.models.torch.layers">
<span id="batchflow-models-torch-layers"></span><h1>batchflow.models.torch.layers<a class="headerlink" href="#module-batchflow.models.torch.layers" title="Permalink to this headline">¶</a></h1>
<p>Contains custom PyTorch layers</p>
<dl class="class">
<dt id="batchflow.models.torch.layers.Activation">
<em class="property">class </em><code class="descname">Activation</code><span class="sig-paren">(</span><em>activation</em>, <em>*args</em>, <em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Activation"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Activation" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A proxy activation module</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em>, </em><em>nn.Module</em><em>, </em><em>callable</em><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – <p>an activation function, can be</p>
<ul>
<li>None - for identity function <cite>f(x) = x</cite></li>
<li>str - a name from <cite>torch.nn</cite></li>
<li>an instance of activation module (e.g. <cite>torch.nn.ReLU()</cite> or <cite>torch.nn.ELU(alpha=2.0)</cite>)</li>
<li>a class of activation module (e.g. <cite>torch.nn.ReLU</cite> or <cite>torch.nn.ELU</cite>)</li>
<li>a callable (e.g. <cite>F.relu</cite> or your custom function)</li>
</ul>
</li>
<li><strong>args</strong> – <p>custom positional arguments passed to</p>
<ul>
<li>a module class when creating a function</li>
<li>a callable during forward pass</li>
</ul>
</li>
<li><strong>kwargs</strong> – custom named arguments</li>
</ul>
</td>
</tr>
</tbody>
</table>
<dl class="method">
<dt id="batchflow.models.torch.layers.Activation.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Activation.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Activation.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make forward pass</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.AdaptivePool">
<em class="property">class </em><code class="descname">AdaptivePool</code><span class="sig-paren">(</span><em>op='max'</em>, <em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#AdaptivePool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.AdaptivePool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._Pool</span></code></p>
<p>Multi-dimensional adaptive pooling layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.BatchNorm">
<em class="property">class </em><code class="descname">BatchNorm</code><span class="sig-paren">(</span><em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#BatchNorm"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.BatchNorm" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-dimensional batch normalization layer</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.BatchNorm.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#BatchNorm.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.BatchNorm.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Conv">
<em class="property">class </em><code class="descname">Conv</code><span class="sig-paren">(</span><em>filters</em>, <em>kernel_size</em>, <em>stride=None</em>, <em>strides=None</em>, <em>padding='same'</em>, <em>dilation=None</em>, <em>dilation_rate=None</em>, <em>groups=None</em>, <em>bias=True</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Conv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Conv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._Conv</span></code></p>
<p>Multi-dimensional convolutional layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.ConvBlock">
<em class="property">class </em><code class="descname">ConvBlock</code><span class="sig-paren">(</span><em>inputs=None</em>, <em>layout=''</em>, <em>filters=None</em>, <em>kernel_size=3</em>, <em>strides=1</em>, <em>padding='same'</em>, <em>dilation_rate=1</em>, <em>depth_multiplier=1</em>, <em>activation='relu'</em>, <em>pool_size=2</em>, <em>pool_strides=2</em>, <em>dropout_rate=0</em>, <em>units=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/conv_block.html#ConvBlock"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.ConvBlock" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Complex multi-dimensional block with a sequence of convolutions, batch normalization, activation, pooling,
dropout, dense and other layers.</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first simple">
<li><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>a sequence of operations:</p>
<ul>
<li>c - convolution</li>
<li>t - transposed convolution</li>
<li>C - separable convolution</li>
<li>T - separable transposed convolution</li>
<li>f - dense (fully connected)</li>
<li>n - batch normalization</li>
<li>a - activation</li>
<li>p - pooling (default is max-pooling)</li>
<li>v - average pooling</li>
<li>P - global pooling (default is max-pooling)</li>
<li>V - global average pooling</li>
<li>d - dropout</li>
<li>D - alpha dropout</li>
<li>X - upsample with subpixel convolution (<code class="xref py py-func docutils literal notranslate"><span class="pre">SubPixelConv()</span></code>)</li>
</ul>
<p>Default is ‘’.</p>
</li>
<li><strong>filters</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the number of filters in the output tensor</li>
<li><strong>kernel_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – kernel size</li>
<li><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – name of the layer that will be used as a scope.</li>
<li><strong>units</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – the number of units in the dense layer</li>
<li><strong>strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Default is 1.</li>
<li><strong>padding</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – padding mode, can be ‘same’ or ‘valid’. Default - ‘same’,</li>
<li><strong>dilation_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Default is 1.</li>
<li><strong>depth_multipler</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Filters factor for separable convolutions</li>
<li><strong>activation</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a><em> or </em><em>callable</em>) – Default is ‘relu’.</li>
<li><strong>pool_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Default is 2.</li>
<li><strong>pool_strides</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – Default is 2.</li>
<li><strong>pool_op</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – pooling operation (‘max’, ‘mean’, ‘frac’)</li>
<li><strong>dropout_rate</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#float" title="(in Python v3.7)"><em>float</em></a>) – Default is 0.</li>
<li><strong>units</strong> – number of neurons in dense layers</li>
<li><strong>factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a><em> or </em><em>tuple of int</em>) – upsampling factor</li>
<li><strong>shape</strong> (<em>tuple of int</em>) – a shape to upsample to</li>
<li><strong>inputs</strong> (<em>torch.Tensor</em><em>, </em><em>torch.nn.Module</em><em>, </em><a class="reference external" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.html#numpy.ndarray" title="(in NumPy v1.15)"><em>numpy.ndarray</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#tuple" title="(in Python v3.7)"><em>tuple</em></a>) – shape or an example of input tensor to infer shape</li>
<li><strong>dense</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – common parameters for dense layers, like initializers, regularalizers, etc</li>
<li><strong>conv</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – common parameters for convolution layers, like initializers, regularalizers, etc</li>
<li><strong>transposed_conv</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – common parameters for transposed conv layers, like initializers, regularalizers, etc</li>
<li><strong>batch_norm</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – common parameters for batch normalization layers, like momentum, intiializers, etc</li>
<li><strong>pooling</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a>) – common parameters for pooling layers, like initializers, regularalizers, etc</li>
<li><strong>dropout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#dict" title="(in Python v3.7)"><em>dict</em></a><em> or </em><a class="reference external" href="https://docs.python.org/3/library/constants.html#None" title="(in Python v3.7)"><em>None</em></a>) – common parameters for dropout layers, like noise_shape, etc</li>
</ul>
</td>
</tr>
<tr class="field-even field"><th class="field-name">Returns:</th><td class="field-body"><p class="first"></p>
</td>
</tr>
<tr class="field-odd field"><th class="field-name">Return type:</th><td class="field-body"><p class="first last">torch.nn.Module</p>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Notes</p>
<p>When <code class="docutils literal notranslate"><span class="pre">layout</span></code> includes several layers of the same type, each one can have its own parameters,
if corresponding args are passed as lists (not tuples).</p>
<p>Spaces may be used to improve readability.</p>
<p>If common layer parameters (dense, conv, etc) is set to False or includes a key ‘disable’ set to True,
all the layers of that type will be excluded whatsoever.</p>
<p>Such a feature comes in handy for analyzing various model architectures and configurations
(see <a class="reference internal" href="batchflow.research.html#batchflow.research.Research" title="batchflow.research.Research"><code class="xref py py-class docutils literal notranslate"><span class="pre">Research</span></code></a>).</p>
<p class="rubric">Examples</p>
<p>A simple block: 3x3 conv, batch norm, relu, 2x2 max-pooling with stride 2:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">ConvBlock</span><span class="p">(</span><span class="s1">&#39;cnap&#39;</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="mi">32</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">28</span><span class="p">,</span> <span class="mi">28</span><span class="p">))</span>
</pre></div>
</div>
<p>A canonical bottleneck block (1x1, 3x3, 1x1 conv with relu in-between):</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="s1">&#39;nac nac nac&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">inputs</span><span class="o">=</span><span class="n">images_tensor</span><span class="p">)</span>
</pre></div>
</div>
<p>A complex Nd block:</p>
<ul class="simple">
<li>5x5 conv with 32 filters</li>
<li>relu</li>
<li>3x3 conv with 32 filters</li>
<li>relu</li>
<li>3x3 conv with 64 filters and a spatial stride 2</li>
<li>relu</li>
<li>batch norm</li>
<li>dropout with rate 0.15</li>
</ul>
<p>A simple block with disabled batch-norms to test self-normalization:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="s1">&#39;cna cna cna&#39;</span><span class="p">,</span> <span class="n">filters</span><span class="o">=</span><span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">256</span><span class="p">],</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;selu&#39;</span><span class="p">,</span> <span class="n">batch_norm</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
               <span class="n">inputs</span><span class="o">=</span><span class="n">previous_layer</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">conv_block</span><span class="p">(</span><span class="s1">&#39;ca ca ca nd&#39;</span><span class="p">,</span> <span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">64</span><span class="p">],</span> <span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">strides</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">dropout_rate</span><span class="o">=.</span><span class="mi">15</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">prev_layer</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="batchflow.models.torch.layers.ConvBlock.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/conv_block.html#ConvBlock.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.ConvBlock.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make forward pass</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.ConvTranspose">
<em class="property">class </em><code class="descname">ConvTranspose</code><span class="sig-paren">(</span><em>filters</em>, <em>kernel_size</em>, <em>stride=None</em>, <em>strides=None</em>, <em>padding='same'</em>, <em>dilation=None</em>, <em>dilation_rate=None</em>, <em>groups=None</em>, <em>bias=True</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#ConvTranspose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.ConvTranspose" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._Conv</span></code></p>
<p>Multi-dimensional transposed convolutional layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Dense">
<em class="property">class </em><code class="descname">Dense</code><span class="sig-paren">(</span><em>units=None</em>, <em>out_features=None</em>, <em>bias=True</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Dense"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Dense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A dense layer</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.Dense.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Dense.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Dense.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Make forward pass</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Dropout">
<em class="property">class </em><code class="descname">Dropout</code><span class="sig-paren">(</span><em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Dropout"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Dropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-dimensional dropout layer</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.Dropout.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Dropout.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Dropout.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Flatten">
<em class="property">class </em><code class="descname">Flatten</code><span class="sig-paren">(</span><em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Flatten"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Flatten" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>A module which reshapes inputs into 2-dimension (batch_items, features)</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.Flatten.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Flatten.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Flatten.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.GlobalPool">
<em class="property">class </em><code class="descname">GlobalPool</code><span class="sig-paren">(</span><em>inputs=None</em>, <em>op='max'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#GlobalPool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.GlobalPool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Multi-dimensional global pooling layer</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.GlobalPool.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#GlobalPool.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.GlobalPool.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Identity">
<em class="property">class </em><code class="descname">Identity</code><span class="sig-paren">(</span><em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Identity"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Identity" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Module which just returns its inputs</p>
<p class="rubric">Notes</p>
<p>It slows training and inference so you should have a very good reason to use it.
For instance, this could be a good option to replace some other module when debugging.</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.Identity.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Identity.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Identity.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Interpolate">
<em class="property">class </em><code class="descname">Interpolate</code><span class="sig-paren">(</span><em>*args</em>, <em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Interpolate"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Interpolate" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Upsample inputs with a given factor</p>
<p class="rubric">Notes</p>
<p>This is just a wrapper around <code class="docutils literal notranslate"><span class="pre">F.interpolate</span></code>.</p>
<p>For brevity <code class="docutils literal notranslate"><span class="pre">mode</span></code> can be specified with the first letter only: ‘n’, ‘l’, ‘b’, ‘t’.</p>
<p>All the parameters should the specified as keyword arguments (i.e. with names and values).</p>
<dl class="method">
<dt id="batchflow.models.torch.layers.Interpolate.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Interpolate.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Interpolate.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.PixelShuffle">
<em class="property">class </em><code class="descname">PixelShuffle</code><span class="sig-paren">(</span><em>upscale_factor=None</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#PixelShuffle"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.PixelShuffle" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.pixelshuffle.PixelShuffle</span></code></p>
<p>Resize input tensor with depth to space operation</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Pool">
<em class="property">class </em><code class="descname">Pool</code><span class="sig-paren">(</span><em>inputs=None</em>, <em>op='max'</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#Pool"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Pool" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._Pool</span></code></p>
<p>Multi-dimensional pooling layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.SeparableConv">
<em class="property">class </em><code class="descname">SeparableConv</code><span class="sig-paren">(</span><em>filters</em>, <em>kernel_size</em>, <em>stride=None</em>, <em>strides=None</em>, <em>padding='same'</em>, <em>dilation=None</em>, <em>dilation_rate=None</em>, <em>bias=True</em>, <em>depth_multiplier=1</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#SeparableConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.SeparableConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._SeparableConv</span></code></p>
<p>Multi-dimensional separable convolutional layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.SeparableConvTranspose">
<em class="property">class </em><code class="descname">SeparableConvTranspose</code><span class="sig-paren">(</span><em>filters</em>, <em>kernel_size</em>, <em>stride=None</em>, <em>strides=None</em>, <em>padding='same'</em>, <em>dilation=None</em>, <em>dilation_rate=None</em>, <em>bias=True</em>, <em>depth_multiplier=1</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#SeparableConvTranspose"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.SeparableConvTranspose" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core._SeparableConv</span></code></p>
<p>Multi-dimensional transposed separable convolutional layer</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.SubPixelConv">
<em class="property">class </em><code class="descname">SubPixelConv</code><span class="sig-paren">(</span><em>upscale_factor=None</em>, <em>inputs=None</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/core.html#SubPixelConv"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.SubPixelConv" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">batchflow.models.torch.layers.core.PixelShuffle</span></code></p>
<p>An alias for PixelShuffle</p>
</dd></dl>

<dl class="class">
<dt id="batchflow.models.torch.layers.Upsample">
<em class="property">class </em><code class="descname">Upsample</code><span class="sig-paren">(</span><em>factor=2</em>, <em>shape=None</em>, <em>layout='b'</em>, <em>*args</em>, <em>inputs=None</em>, <em>**kwargs</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/upsample.html#Upsample"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Upsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Upsample inputs with a given factor</p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field-odd field"><th class="field-name">Parameters:</th><td class="field-body"><ul class="first last simple">
<li><strong>factor</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.7)"><em>int</em></a>) – an upsamping scale</li>
<li><strong>shape</strong> (<em>tuple of int</em>) – a shape to upsample to (used by bilinear and NN resize)</li>
<li><strong>layout</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.7)"><em>str</em></a>) – <p>resizing technique, a sequence of:</p>
<ul>
<li>b - bilinear resize</li>
<li>N - nearest neighbor resize</li>
<li>t - transposed convolution</li>
<li>T - separable transposed convolution</li>
<li>X - subpixel convolution</li>
</ul>
<p>all other <code class="xref py py-class docutils literal notranslate"><span class="pre">ConvBlock</span></code> layers are also allowed.</p>
</li>
<li><strong>inputs</strong> – an input tensor</li>
</ul>
</td>
</tr>
</tbody>
</table>
<p class="rubric">Examples</p>
<p>A simple bilinear upsampling:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">Upsample</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>Upsampling with non-linear normalized transposed convolution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">Upsample</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="s1">&#39;nat&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<p>Subpixel convolution:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">Upsample</span><span class="p">(</span><span class="n">layout</span><span class="o">=</span><span class="s1">&#39;X&#39;</span><span class="p">,</span> <span class="n">factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">inputs</span><span class="o">=</span><span class="n">inputs</span><span class="p">)</span>
</pre></div>
</div>
<dl class="method">
<dt id="batchflow.models.torch.layers.Upsample.forward">
<code class="descname">forward</code><span class="sig-paren">(</span><em>x</em><span class="sig-paren">)</span><a class="reference internal" href="../_modules/batchflow/models/torch/layers/upsample.html#Upsample.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#batchflow.models.torch.layers.Upsample.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

</dd></dl>

</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related" role="navigation" aria-label="related navigation">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="batchflow.research.html" title="dataset.research"
             >next</a> |</li>
        <li class="right" >
          <a href="batchflow.models.torch.html" title="batchflow.models.torch"
             >previous</a> |</li>
        <li class="nav-item nav-item-0"><a href="../index.html">BatchFlow 0.3.0 documentation</a> &#187;</li>
          <li class="nav-item nav-item-1"><a href="batchflow.html" >API</a> &#187;</li>
          <li class="nav-item nav-item-2"><a href="batchflow.models.html" >batchflow.models</a> &#187;</li>
          <li class="nav-item nav-item-3"><a href="batchflow.models.torch.html" >batchflow.models.torch</a> &#187;</li> 
      </ul>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Analysis Center.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.8.3.
    </div>
  </body>
</html>